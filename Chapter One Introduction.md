#  简介

# 1.1 存储墙

图1.1显示了过去四十年来处理器性能与内存性能之间的日益扩大的差距。微体系结构、电路和制造技术方面的创新导致了这一时期内处理器性能呈指数级增长。与此同时，DRAM主要受益于密度的增长，而内存速度的提高仅限于名义上的改进。虽然未来的预测表明，处理器性能提升可能不会以相同的速度继续下去，但目前的性能差距仍需要在未来几年通过缓解长内存访问延迟的技术来弥补。

历史上，计算机架构师一直试图通过使用多级高速缓存来弥合这一性能差距。图 1.2 描述了现代计算机高速缓存层次结构的组织原理。该层次结构由高速缓存组成，每层在容量和低延迟之间进行权衡。高速缓存层次结构的作用是通过经常在高速缓存中处理内存请求来提高平均内存访问时间，从而避免 DRAM 的长时间访问延迟。靠近内核的高速缓存级别较小但速度更快。每一层都为最近访问的数据块提供临时存储空间，以降低有效内存访问延迟。数据块越接近内核，访问延迟就越小。我们把最靠近内核的高速缓存称为 L1 缓存，然后按顺序编号，最后一个高速缓存级别被称为 LLC（Last Level Cache）。

这种层次结构依赖于两种类型的内存引用局部性。时间局部性指的是最近访问过的且可能再次访问的内存。空间局部性指的是物理上靠近且可能被访问的内存，因为邻近指令和数据通常相关。

虽然局部性作为一个概念可以充分利用并减少有效内存访问延迟，但它依赖于两个基本前提，对于所有工作负载不一定成立，尤其是当高速缓存层次结构加深时。第一个前提是所有工作负载和访问模式都适合一个大小的高速缓存。事实上，现代工作负载的容量需求差异很大，不同的工作负载从不同级别的高速缓存容量和速度的权衡中受益。第二个前提是为所有工作负载分配和替换高速缓存条目（通常按需分配，并替换最近未使用过的条目）的一种策略。然而，再次强调，决定哪些块应保留在高速缓存中的简单策略可能对大量变化的内存访问模式表现不佳。

为克服内存墙，已经提出了许多算法、编译器级和系统软件级到硬件的各种技术。这些技术包括缓存盲算法、编译器级别的代码和数据布局优化以及以硬件为中心的方法。此外，还提出了许多基于软件的技术来预取。在本书中，我们关注于基于硬件的指令和数据预取技术。为了更全面地了解存储系统，我们引用了雅各布的综合讲座[4]。

# 1.2 预取技术

预取是隐藏内存访问延迟的一种方法。其核心思想是通过预测后续内存访问需求，提前将所需数据加载到缓存中，从而消除潜在的长延迟。在理想情况下，内存访问不会产生额外开销，性能可达到处理器寄存器级别。然而现实中，预取可能因时机不当或预测错误导致能效浪费，甚至损害性能。

有效的预取机制需满足：
1. 准确预测内存访问地址 
2. 合理选择预取时机  
3. 优化数据放置策略  

## 1.2.1 地址预测

预测正确的内存地址是预取机制面临的一个关键挑战。如果地址预测正确，预取机制将有机会提前获取这些地址并隐藏内存访问延迟。如果地址预测不准确，预取可能会导致缓存层次结构中的污染（即，预取的缓存块会驱逐潜在有用的缓存块）并在内存系统中产生过多的流量和竞争。

预测内存地址可能并不那么简单。数据引用可以是对独立变量的访问或者是对数据结构元素的访问，而引用的本质取决于程序在特定执行实例中正在做什么。有一些算法和数据结构遍历非常适合于重复和可预测的模式（例如，顺序读取数组的每个元素）。同时，也存在一些使内存地址难以预测的情况。这些情况包括但不限于变量访问的交错、多个数据结构以及依赖于控制流的遍历（如搜索二叉树）。

类似地，指令引用将取决于程序是顺序执行还是采取分支（即跟随不连续）。虽然顺序指令获取是直接的，但程序中的控制流行为及其可预测性会影响指令预取的有效性。准确预测地址还取决于执行预取操作的缓存层次级别。在最高级别，处理器与一级缓存之间的接口（图1.2）包含了所有能够实现高度精确预取的内存引用信息，但也可能导致资源浪费，因为记录了那些无论如何都会在第一级缓存命中因而不需要预取的访问的预取信息。相反，在较低的层次级别，访问序列被过滤，仅观察到来自更高级别的未命中。因此，否则有效的预取算法可能会被诸如缓存放置和替换策略的影响所引起的访问序列扰动混淆。

最后，预取策略的激进程度与准确性之间通常存在权衡；更激进的预取将在错误地获取更多地址的情况下，预测处理器实际请求的更高比例的地址。出于这个原因，许多对预取器的评估研究报告了两个关键度量标准，它们共同描述了预取器预测地址的有效性。覆盖率衡量成功预取（即消除需求误击的比例）的显式处理器请求的百分比。准确性衡量由预取器发出但证明是有用的访问的百分比（即所有预取中正确预取的百分比）。许多简单的预取器可以在牺牲准确性的情况下提高覆盖率，而理想的预取器可以同时提供高准确性和覆盖率。

## 1.2.2 预取预览

理想情况下，一个前缀机制会在很早的时候发出前缀请求，并为前缀数据提供足够的存储空间，从而隐藏所有内存访问延迟。然而，在实践中准确预测何时进行前缀是一项重大挑战。即使地址预测正确，如果前缀器提前太多次发出前缀请求，那么在访问之前可能无法使处理器附近的所有预取数据保持足够长的时间。最好的情况是，过早地进行前缀操作会变得无用，因为预读信息会在使用前被从处理器处驱逐出去。在最坏的情况下，它可能会驱逐其他有用的信息（例如其他预读的数据或高级缓存中的有用块）。如果预读太晚了，那么它会降低预读的有效性，因为它会在内存访问时暴露内存访问延迟。在极限情况下，延迟前缀可能导致性能下降，原因是有额外的内存系统流量并且与旨在优先考虑时间敏感的需求访问的机制交互不良。

## 1.2.3  储存预取结果

最简单、也可能是最早的软件数据预取策略，就是像执行任何其他显式加载操作一样，将其加载到处理器寄存器中。许多架构，尤其是现代乱序处理器，在发出加载请求时不会阻塞执行，而是在另一个指令使用了加载值时才阻塞依赖于该加载的指令。这种预取策略通常被称为绑定预取，因为预取发出时，后续对数据的使用就被绑定到了这个值上。这种方法存在一些缺点：(1) 它消耗宝贵的处理器寄存器；(2) 即使内存系统已经过载，硬件仍必须执行预取；(3) 如果预取地址错误（例如，无效地址的预读会导致内存保护故障吗？），就会导致语义上的困难；以及 (4) 还不清楚如何将此策略应用于指令。

相反，大多数硬件预取技术要么直接将预取的值放入缓存层次结构中，要么将其放入补充缓冲区以增强缓存层次结构，并且可以同时访问。在多核和众核系统中，这些缓存和缓冲区参与缓存协议，并且因此，在预读取和随后访问之间的时间间隔内，预读取内存位置的值可能会发生变化；硬件有责任确保访问看到最新的值。这种预读取策略被称为非绑定。在这种情况下，预读取纯粹是为了性能优化，不会影响程序的语义。

本书中讨论的所有硬件预取技术都属于后一种非绑定类。它们的区别在于，它们将预取的数据放在哪里以及如何为新预取的内存腾出空间。




