#  简介

# 1.1 存储墙

图1.1显示了过去四十年来处理器性能与内存性能之间的日益扩大的差距。微体系结构、电路和制造技术方面的创新导致了这一时期内处理器性能呈指数级增长。与此同时，DRAM主要受益于密度的增长，而内存速度的提高仅限于名义上的改进。虽然未来的预测表明，处理器性能提升可能不会以相同的速度继续下去，但目前的性能差距仍需要在未来几年通过缓解长内存访问延迟的技术来弥补。

历史上，计算机架构师一直试图通过使用多级高速缓存来弥合这一性能差距。图 1.2 描述了现代计算机高速缓存层次结构的组织原理。该层次结构由高速缓存组成，每层在容量和低延迟之间进行权衡。高速缓存层次结构的作用是通过经常在高速缓存中处理内存请求来提高平均内存访问时间，从而避免 DRAM 的长时间访问延迟。靠近内核的高速缓存级别较小但速度更快。每一层都为最近访问的数据块提供临时存储空间，以降低有效内存访问延迟。数据块越接近内核，访问延迟就越小。我们把最靠近内核的高速缓存称为 L1 缓存，然后按顺序编号，最后一个高速缓存级别被称为 LLC（Last Level Cache）。

这种层次结构依赖于两种类型的内存引用局部性。时间局部性指的是最近访问过的且可能再次访问的内存。空间局部性指的是物理上靠近且可能被访问的内存，因为邻近指令和数据通常相关。

虽然局部性作为一个概念可以充分利用并减少有效内存访问延迟，但它依赖于两个基本前提，对于所有工作负载不一定成立，尤其是当高速缓存层次结构加深时。第一个前提是所有工作负载和访问模式都适合一个大小的高速缓存。事实上，现代工作负载的容量需求差异很大，不同的工作负载从不同级别的高速缓存容量和速度的权衡中受益。第二个前提是为所有工作负载分配和替换高速缓存条目（通常按需分配，并替换最近未使用过的条目）的一种策略。然而，再次强调，决定哪些块应保留在高速缓存中的简单策略可能对大量变化的内存访问模式表现不佳。

为克服内存墙，已经提出了许多算法、编译器级和系统软件级到硬件的各种技术。这些技术包括缓存盲算法、编译器级别的代码和数据布局优化以及以硬件为中心的方法。此外，还提出了许多基于软件的技术来预取。在本书中，我们关注于基于硬件的指令和数据预取技术。为了更全面地了解存储系统，我们引用了雅各布的综合讲座[4]。

# 1.2 预取

## 1.2.2 预取预览

理想情况下，一个前缀机制会在很早的时候发出前缀请求，并为前缀数据提供足够的存储空间，从而隐藏所有内存访问延迟。然而，在实践中准确预测何时进行前缀是一项重大挑战。即使地址预测正确，如果前缀器提前太多次发出前缀请求，那么在访问之前可能无法使处理器附近的所有预取数据保持足够长的时间。最好的情况是，过早地进行前缀操作会变得无用，因为预读信息会在使用前被从处理器处驱逐出去。在最坏的情况下，它可能会驱逐其他有用的信息（例如其他预读的数据或高级缓存中的有用块）。如果预读太晚了，那么它会降低预读的有效性，因为它会在内存访问时暴露内存访问延迟。在极限情况下，延迟前缀可能导致性能下降，原因是有额外的内存系统流量并且与旨在优先考虑时间敏感的需求访问的机制交互不良。

## 1.2.3  储存预取结果

最简单、也可能是最早的软件数据预取策略，就是像执行任何其他显式加载操作一样，将其加载到处理器寄存器中。许多架构，尤其是现代乱序处理器，在发出加载请求时不会阻塞执行，而是在另一个指令使用了加载值时才阻塞依赖于该加载的指令。这种预取策略通常被称为绑定预取，因为预取发出时，后续对数据的使用就被绑定到了这个值上。这种方法存在一些缺点：(1) 它消耗宝贵的处理器寄存器；(2) 即使内存系统已经过载，硬件仍必须执行预取；(3) 如果预取地址错误（例如，无效地址的预读会导致内存保护故障吗？），就会导致语义上的困难；以及 (4) 还不清楚如何将此策略应用于指令。


